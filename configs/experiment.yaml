# Experiment configuration for VisDrone robustness evaluation

# Reproducibility
seed: 42

# Dataset paths
dataset:
  visdrone_root: "datasets/visdrone"
  visdrone_yolo_root: "datasets/visdrone_yolo"
  corruptions_root: "datasets/visdrone_corrupt"
  
# VisDrone download
visdrone:
  url: "https://github.com/VisDrone/VisDrone-Dataset"
  # Will use direct download links for VisDrone2019-DET
  train_url: "http://aiskyeye.com/download/object-detection-2/VisDrone2019-DET-train.zip"
  val_url: "http://aiskyeye.com/download/object-detection-2/VisDrone2019-DET-val.zip"
  test_url: "http://aiskyeye.com/download/object-detection-2/VisDrone2019-DET-test-dev.zip"
  
# Experiment mode
experiment:
  pilot_mode: false  # Full experiment mode: use standard severities [0,1,2,3,4]
  sample_size: 100  # Number of tiny objects to sample
  one_per_image: true  # Sample only one tiny bbox per image (avoid duplicate images)
  
# Tiny object definition
# Based on empirical testing: YOLO can detect 2500+ pxÂ² objects with >50% rate
# Tested with same_class=False (class mismatch is common with COCO pretrained model)
tiny_objects:
  area_threshold: 2500  # pixels^2 (minimum area - 50x50 pixels, 63.8% detection rate)
  width_threshold: 50  # pixels (minimum width OR height must be >= this)
  height_threshold: 50  # pixels (minimum height OR width must be >= this)
  max_area_threshold: 20000  # pixels^2 (maximum area to keep them "small")
  sample_size: 100  # number of GT boxes to sample
  
# Corruptions
corruptions:
  types: ["fog", "lowlight", "motion_blur"]
  # Full experiment: use standard severities [0, 1, 2, 3, 4]
  severities: [0, 1, 2, 3, 4]  # Standard severity levels
  # Dynamic refinement: if failure detected between severities, subdivide into 10 steps
  dynamic_refinement:
    enabled: true
    subdivision_steps: 10  # Number of steps to subdivide failure region
    failure_threshold: 0.5  # Miss rate threshold to trigger refinement
  
  # Standard severity parameters (severity 0-4)
  fog:
    alpha: [0.0, 0.15, 0.30, 0.45, 0.60]  # fog strength for severities [0, 1, 2, 3, 4]
  lowlight:
    gamma: [1.0, 1.2, 1.4, 1.6, 1.8]  # gamma correction for severities [0, 1, 2, 3, 4] (reduced from [1.0, 1.4, 1.8, 2.2, 2.6])
    brightness_scale: [1.0, 0.90, 0.80, 0.70, 0.60]  # brightness scaling for severities [0, 1, 2, 3, 4] (increased from [1.0, 0.85, 0.70, 0.55, 0.40])
  motion_blur:
    kernel_length: [0, 3, 6, 9, 12]  # kernel length for severities [0, 1, 2, 3, 4] (reduced from [0, 7, 13, 19, 25])
    angle: 0  # degrees, or use hash-based per image
    
# Models
# Full experiment: can enable all models
models:
  yolo_generic:
    type: "yolo"
    architecture: "yolov8s"
    pretrained: "yolov8s.pt"
    fine_tuned: false
    checkpoint: null
  
  # Disabled for pilot experiment
  # yolo_ft:
  #   type: "yolo"
  #   architecture: "yolov8s"
  #   pretrained: "yolov8s.pt"
  #   fine_tuned: true
  #   checkpoint: "results/models/yolo_ft_visdrone.pt"
  #   train_epochs: 100
  #   train_imgsz: 640
  #   train_batch: 16
  # 
  # rt_detr:
  #   type: "rtdetr"
  #   architecture: "rtdetr-l"
  #   pretrained: "rtdetr-l.pt"
  #   fine_tuned: false
  #   checkpoint: null
    
# Inference settings
inference:
  imgsz: 640
  conf_thres: 0.01  # Lowered for tiny object detection (was 0.25)
  iou_thres: 0.45
  
# Single image mode (no frame sequences)
# Frame sequence settings removed - using single images only
  
# Evaluation
evaluation:
  splits: ["val"]  # primary split
  iou_thresholds: [0.5, 0.5, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95]  # for mAP@0.5:0.95
  tiny_match_iou_threshold: 0.3  # Relaxed for tiny objects (was 0.5) - IoU >= 0.3 for match
  tiny_match_same_class: false  # Set to false: COCO pretrained YOLO has class mismatch with VisDrone
  
# Risk region detection (automatic identification)
risk_detection:
  map_drop_threshold: 0.15  # absolute drop from severity 0
  miss_rate_threshold: 0.25  # miss rate threshold for risk region (25% - realistic for tiny objects)
  score_drop_threshold: 0.2  # score drop threshold
  iou_drop_threshold: 0.2  # IoU drop threshold
  instability_threshold: 0.3  # variance threshold for instability detection (across severities)
  
# Grad-CAM (failure-event based)
gradcam:
  enabled: true
  target_layer: "model.18.cv2.conv"  # Backbone last C2f block's cv2 conv (stable single feature map, avoids concat)
  top_k_percent: 10
  save_samples: true
  max_samples: 20
  metrics: ["energy_in_bbox", "activation_spread", "entropy", "center_shift"]  # CAM distribution metrics
  # Dynamic refinement: analyze failure region in detail
  dynamic_refinement:
    enabled: true
    detect_failure_region: true  # Detect "explosive" failure region (e.g., severity 2-3)
    subdivision_steps: 10  # Subdivide failure region into N steps
    failure_detection_threshold: 0.3  # CAM metric change threshold to detect failure
  
# Results paths
results:
  root: "results"
  metrics_csv: "results/metrics_dataset.csv"
  tiny_curves_csv: "results/tiny_curves.csv"
  tiny_records_csv: "results/tiny_records.csv"
  gradcam_metrics_csv: "results/gradcam_metrics.csv"
  report_md: "results/report.md"
  
# LLM report
llm_report:
  model: "gpt-4o-mini"
  temperature: 0.0
  max_tokens: 4000
