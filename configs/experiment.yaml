# Experiment configuration for VisDrone robustness evaluation

# Reproducibility
seed: 42

# Dataset paths
dataset:
  visdrone_root: "datasets/visdrone"
  visdrone_yolo_root: "datasets/visdrone_yolo"
  corruptions_root: "datasets/visdrone_corrupt"
  
# VisDrone download
visdrone:
  url: "https://github.com/VisDrone/VisDrone-Dataset"
  # Will use direct download links for VisDrone2019-DET
  train_url: "http://aiskyeye.com/download/object-detection-2/VisDrone2019-DET-train.zip"
  val_url: "http://aiskyeye.com/download/object-detection-2/VisDrone2019-DET-val.zip"
  test_url: "http://aiskyeye.com/download/object-detection-2/VisDrone2019-DET-test-dev.zip"
  
# Experiment mode (Option A - reviewer-friendly)
# Tiny object 샘플 N개에 대해 3개 변조 유형(fog/lowlight/motion_blur)을 5단계(Level 0-4)로 적용.
# N=500: 500 × 3 × 5 = 7500 frames (2500 per corruption). Level 0 = reference only (no duplicate file).
experiment:
  pilot_mode: false  # Full experiment mode: use standard severities [0,1,2,3,4]
  sample_size: 500   # Legacy: overridden by target_tiny_objects
  target_tiny_objects: 500  # Tiny object sample size. 500 × 3 × 5 = 7500 frames (2500 per corruption).
  max_images: null   # Max images to scan for tiny objects (null = no limit)
  one_per_image: false  # Allow multiple tiny bboxes per image when sampling 500 objects
  
# Tiny object definition
# Based on empirical testing: YOLO can detect 2500+ px² objects with >50% rate
# Tested with same_class=False (class mismatch is common with COCO pretrained model)
tiny_objects:
  area_threshold: 2500  # pixels^2 (minimum area - 50x50 pixels, 63.8% detection rate)
  width_threshold: 50  # pixels (minimum width OR height must be >= this)
  height_threshold: 50  # pixels (minimum height OR width must be >= this)
  max_area_threshold: 20000  # pixels^2 (maximum area to keep them "small")
  sample_size: 100  # number of GT boxes to sample
  
# Corruptions
corruptions:
  types: ["fog", "lowlight", "motion_blur"]
  # Full experiment: use standard severities [0, 1, 2, 3, 4]
  severities: [0, 1, 2, 3, 4]  # Standard severity levels
  # Dynamic refinement: if failure detected between severities, subdivide into 10 steps
  dynamic_refinement:
    enabled: true
    subdivision_steps: 10  # Number of steps to subdivide failure region
    failure_threshold: 0.5  # Miss rate threshold to trigger refinement
  
  # Standard severity parameters (severity 0-4) - INCREASED STRENGTH
  fog:
    alpha: [0.0, 0.25, 0.50, 0.75, 0.90]  # fog strength for severities [0, 1, 2, 3, 4] - INCREASED from [0.0, 0.15, 0.30, 0.45, 0.60]
  lowlight:
    gamma: [1.0, 1.5, 2.0, 2.5, 3.0]  # gamma correction for severities [0, 1, 2, 3, 4] - INCREASED from [1.0, 1.2, 1.4, 1.6, 1.8]
    brightness_scale: [1.0, 0.75, 0.50, 0.35, 0.20]  # brightness scaling for severities [0, 1, 2, 3, 4] - DECREASED from [1.0, 0.90, 0.80, 0.70, 0.60]
  motion_blur:
    kernel_length: [0, 5, 10, 15, 20]  # kernel length for severities [0, 1, 2, 3, 4] - INCREASED from [0, 3, 6, 9, 12]
    angle: 0  # degrees, or use hash-based per image
    
# Models
# Full experiment: 3 models (Generic, Fine-tuned, RT-DETR)
models:
  yolo_generic:
    type: "yolo"
    architecture: "yolov8s"
    pretrained: "yolov8s.pt"
    fine_tuned: false
    checkpoint: null
  
  yolo_ft:
    type: "yolo"
    architecture: "yolov8s"
    pretrained: "yolov8s.pt"
    fine_tuned: true
    checkpoint: "results/models/yolo_ft_visdrone.pt"
    train_epochs: 100
    train_imgsz: 640
    train_batch: 16
  
  rt_detr:
    type: "rtdetr"
    architecture: "rtdetr-l"
    pretrained: "rtdetr-l.pt"
    fine_tuned: false
    checkpoint: null
    
# Inference settings
inference:
  imgsz: 640
  conf_thres: 0.01  # Lowered for tiny object detection (was 0.25)
  iou_thres: 0.45
  
# Single image mode (no frame sequences)
# Frame sequence settings removed - using single images only
  
# Evaluation
evaluation:
  splits: ["val"]  # primary split
  iou_thresholds: [0.5, 0.5, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95]  # for mAP@0.5:0.95
  tiny_match_iou_threshold: 0.3  # Relaxed for tiny objects (was 0.5) - IoU >= 0.3 for match
  tiny_match_same_class: false  # Set to false: COCO pretrained YOLO has class mismatch with VisDrone
  
# Risk region detection (automatic identification)
risk_detection:
  map_drop_threshold: 0.15  # absolute drop from severity 0
  miss_rate_threshold: 0.25  # miss rate threshold for risk region (25% - realistic for tiny objects)
  score_drop_threshold: 0.2  # absolute score drop threshold
  score_drop_ratio: 0.9  # RQ1: relative score drop (score(sev)/score0 < r). 0.9 = more events, 0.5 = stronger drop only
  iou_drop_threshold: 0.2  # absolute IoU drop threshold
  score_drop_relative_threshold: 0.15  # relative score drop threshold (15% of baseline) - useful for lowlight
  iou_drop_relative_threshold: 0.15  # relative IoU drop threshold (15% of baseline) - useful for lowlight
  instability_threshold: 0.3  # variance threshold for instability detection (across severities)
  
# Grad-CAM (failure-event based)
# B-1/B-3: CAM coverage - n_expected_frames = severity window length (not always 5).
# cam_mode: full (all 0..4) | risk_window (onset-1..onset+1) | stratified (sample). Currently risk_events define window.
gradcam:
  enabled: true
  # Layer configuration (primary/secondary approach)
  layers:
    primary:
      name: "model.9.cv2.conv"  # CRITICAL: Backbone layer (not detect head) - more stable than model.18
      # YOLOv8 structure: model.0-9 = backbone, model.10-21 = neck, model.22-24 = head
      # model.9 is the last backbone C2f block before neck - most stable for CAM
      role: "primary"  # Main layer for analysis
      required: true  # Must succeed
    # secondary:
    #   name: "model.6.cv2.conv"  # Alternative backbone layer (mid-backbone, optional)
    #   role: "secondary"  # Supplementary layer
    #   required: false  # Optional, can fail
    # CRITICAL: Disabled secondary for quick success test - use primary only
  # Quality Gate (QC) thresholds
  quality_gate:
    finite_ratio_threshold: 0.99  # >99% of values must be finite (not NaN/inf)
    cam_sum_epsilon: 1e-8  # CRITICAL: Reduced from 1e-6 to 1e-8 for debugging (allow very small CAMs to pass)
    cam_var_epsilon: 1e-10  # CRITICAL: Reduced from 1e-8 to 1e-10 for debugging (allow near-flat CAMs to pass)
  top_k_percent: 10
  save_samples: true
  max_samples: null  # RQ1: null = process all risk events. Set to number to cap (e.g. 20 for debug).
  metrics: ["energy_in_bbox", "activation_spread", "entropy", "center_shift"]  # CAM distribution metrics
  # Dynamic refinement: analyze failure region in detail
  dynamic_refinement:
    enabled: true
    detect_failure_region: true  # Detect "explosive" failure region (e.g., severity 2-3)
    subdivision_steps: 10  # Subdivide failure region into N steps
    failure_detection_threshold: 0.3  # CAM metric change threshold to detect failure
  
# Results paths
results:
  root: "results"
  metrics_csv: "results/metrics_dataset.csv"
  tiny_curves_csv: "results/tiny_curves.csv"
  tiny_records_csv: "results/tiny_records.csv"
  gradcam_metrics_csv: "results/gradcam_metrics.csv"
  report_md: "results/report.md"
  
# LLM report
llm_report:
  model: "gpt-4o-mini"
  temperature: 0.0
  max_tokens: 4000
